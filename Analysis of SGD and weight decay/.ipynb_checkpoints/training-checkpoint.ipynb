{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython extension to reload modules before executing user code.\n",
    "# 'autoreload' reloads modules automatically before entering the execution of code typed at the IPython prompt.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed initialization (for reproductible results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# Setting the seed for NumPy generated random numbers\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Setting the seed for Python random numbers\n",
    "import random as rn\n",
    "rn.seed(0)\n",
    "\n",
    "# Setting the seed for TensorFlow random numbers\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting best GPU to execute on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gpustat\n",
    "\n",
    "stats = gpustat.GPUStatCollection.new_query()\n",
    "ids = map(lambda gpu: int(gpu.entry['index']), stats)\n",
    "ratios = map(lambda gpu: float(gpu.entry['memory.used'])/float(gpu.entry['memory.total']), stats)\n",
    "bestGPU = min(zip(ids, ratios), key=lambda x: x[1])[0]\n",
    "\n",
    "print(\"setGPU: Setting GPU to: {}\".format(bestGPU))\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(bestGPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User defined packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from data_utils import import_cifar\n",
    "from models import VGG16_Vanilla, VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras.models import clone_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "weights = defaultdict(list)\n",
    "histories = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid), (x_test, y_test) = import_cifar(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 without weight decay nor dropout\n",
    "vgg16_vanilla = VGG16_Vanilla(input_shape=(32,32,3), num_classes=num_classes)\n",
    "vgg16_vanilla.save_weights(\"../weights/initial/VGG16_Vanilla.h5\")\n",
    "\n",
    "weights[vgg16_vanilla] = [[layer.get_weights() for layer in vgg16_vanilla.layers]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 with weight decay and dropout\n",
    "vgg16 = VGG16(input_shape=(32,32,3), num_classes=num_classes, weight_decay=0.005)\n",
    "vgg16.save_weights(\"../weights/initial/VGG16.h5\")\n",
    "\n",
    "weights[vgg16] = [[layer.get_weights() for layer in vgg16.layers]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    # Training parameters\n",
    "    batch_size = 1024\n",
    "    epochs = 100\n",
    "    lr = 0.1\n",
    "    \n",
    "    # Function that is going to be called after each epoch \n",
    "    # Decreases the learning rate\n",
    "    def lr_scheduler(epoch):\n",
    "        new_lr = lr * (0.9 ** epoch)\n",
    "        print('new learning rate: {}'.format(new_lr))\n",
    "        return new_lr\n",
    "    \n",
    "    reduce_lr = callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "    # Optimization details\n",
    "    sgd = optimizers.SGD(lr=lr, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(x=x_train, \n",
    "                        y=y_train, \n",
    "                        batch_size=batch_size, \n",
    "                        epochs=epochs, \n",
    "                        verbose=1, \n",
    "                        callbacks=[EarlyStopping(monitor='val_loss', patience=5), reduce_lr],  \n",
    "                        validation_data=(x_valid, y_valid))\n",
    "    \n",
    "    histories[model].append(history)\n",
    "    weights[model].append([layer.get_weights() for layer in model.layers])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "new learning rate: 0.1\n",
      "50000/50000 [==============================] - 28s 561us/step - loss: 35.1742 - acc: 0.1964 - val_loss: 28.6031 - val_acc: 0.1318\n",
      "Epoch 2/100\n",
      "new learning rate: 0.09000000000000001\n",
      "50000/50000 [==============================] - 15s 305us/step - loss: 18.6243 - acc: 0.3158 - val_loss: 12.6146 - val_acc: 0.0870\n",
      "Epoch 3/100\n",
      "new learning rate: 0.08100000000000002\n",
      "50000/50000 [==============================] - 15s 307us/step - loss: 8.5334 - acc: 0.3868 - val_loss: 7.0797 - val_acc: 0.0976\n",
      "Epoch 4/100\n",
      "new learning rate: 0.0729\n",
      "50000/50000 [==============================] - 15s 307us/step - loss: 4.7472 - acc: 0.4628 - val_loss: 4.6812 - val_acc: 0.1024\n",
      "Epoch 5/100\n",
      "new learning rate: 0.06561\n",
      "50000/50000 [==============================] - 16s 315us/step - loss: 3.1577 - acc: 0.5311 - val_loss: 3.8610 - val_acc: 0.1024\n",
      "Epoch 6/100\n",
      "new learning rate: 0.05904900000000001\n",
      "50000/50000 [==============================] - 16s 317us/step - loss: 2.7431 - acc: 0.5386 - val_loss: 3.7972 - val_acc: 0.1016\n",
      "Epoch 7/100\n",
      "new learning rate: 0.05314410000000001\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 2.3468 - acc: 0.6112 - val_loss: 3.5035 - val_acc: 0.1206\n",
      "Epoch 8/100\n",
      "new learning rate: 0.04782969000000001\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 1.9375 - acc: 0.6614 - val_loss: 3.3136 - val_acc: 0.1188\n",
      "Epoch 9/100\n",
      "new learning rate: 0.04304672100000001\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 1.7510 - acc: 0.6858 - val_loss: 3.1715 - val_acc: 0.1658\n",
      "Epoch 10/100\n",
      "new learning rate: 0.03874204890000001\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 1.5746 - acc: 0.7206 - val_loss: 3.0025 - val_acc: 0.2494\n",
      "Epoch 11/100\n",
      "new learning rate: 0.03486784401000001\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 1.4666 - acc: 0.7570 - val_loss: 3.0912 - val_acc: 0.1608\n",
      "Epoch 12/100\n",
      "new learning rate: 0.031381059609000006\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 1.5516 - acc: 0.7297 - val_loss: 3.4253 - val_acc: 0.1328\n",
      "Epoch 13/100\n",
      "new learning rate: 0.028242953648100012\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 1.6610 - acc: 0.7391 - val_loss: 2.7652 - val_acc: 0.3338\n",
      "Epoch 14/100\n",
      "new learning rate: 0.02541865828329001\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 1.6041 - acc: 0.7587 - val_loss: 1.8593 - val_acc: 0.6908\n",
      "Epoch 15/100\n",
      "new learning rate: 0.02287679245496101\n",
      "50000/50000 [==============================] - 15s 308us/step - loss: 1.4215 - acc: 0.7935 - val_loss: 1.8863 - val_acc: 0.6606\n",
      "Epoch 16/100\n",
      "new learning rate: 0.02058911320946491\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 1.3255 - acc: 0.8064 - val_loss: 1.7546 - val_acc: 0.6742\n",
      "Epoch 17/100\n",
      "new learning rate: 0.018530201888518418\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 1.1896 - acc: 0.8329 - val_loss: 1.8238 - val_acc: 0.6154\n",
      "Epoch 18/100\n",
      "new learning rate: 0.016677181699666577\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 1.1402 - acc: 0.8356 - val_loss: 1.8317 - val_acc: 0.6236\n",
      "Epoch 19/100\n",
      "new learning rate: 0.015009463529699918\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 1.0673 - acc: 0.8476 - val_loss: 1.8700 - val_acc: 0.5928\n",
      "Epoch 20/100\n",
      "new learning rate: 0.013508517176729929\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 1.0224 - acc: 0.8562 - val_loss: 1.3786 - val_acc: 0.7374\n",
      "Epoch 21/100\n",
      "new learning rate: 0.012157665459056936\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.9733 - acc: 0.8611 - val_loss: 1.4452 - val_acc: 0.7108\n",
      "Epoch 22/100\n",
      "new learning rate: 0.010941898913151242\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.9043 - acc: 0.8783 - val_loss: 1.2745 - val_acc: 0.7540\n",
      "Epoch 23/100\n",
      "new learning rate: 0.00984770902183612\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 0.8430 - acc: 0.8929 - val_loss: 1.2345 - val_acc: 0.7668\n",
      "Epoch 24/100\n",
      "new learning rate: 0.008862938119652507\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.7959 - acc: 0.8986 - val_loss: 1.0896 - val_acc: 0.8016\n",
      "Epoch 25/100\n",
      "new learning rate: 0.007976644307687256\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.7438 - acc: 0.9112 - val_loss: 1.2153 - val_acc: 0.7652\n",
      "Epoch 26/100\n",
      "new learning rate: 0.00717897987691853\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.7108 - acc: 0.9166 - val_loss: 0.9993 - val_acc: 0.8196\n",
      "Epoch 27/100\n",
      "new learning rate: 0.006461081889226678\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.6820 - acc: 0.9216 - val_loss: 0.9685 - val_acc: 0.8306\n",
      "Epoch 28/100\n",
      "new learning rate: 0.00581497370030401\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 0.6449 - acc: 0.9313 - val_loss: 0.9196 - val_acc: 0.8400\n",
      "Epoch 29/100\n",
      "new learning rate: 0.00523347633027361\n",
      "50000/50000 [==============================] - 16s 316us/step - loss: 0.6164 - acc: 0.9367 - val_loss: 0.8976 - val_acc: 0.8478\n",
      "Epoch 30/100\n",
      "new learning rate: 0.004710128697246249\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.5902 - acc: 0.9418 - val_loss: 0.9034 - val_acc: 0.8510\n",
      "Epoch 31/100\n",
      "new learning rate: 0.004239115827521624\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.5648 - acc: 0.9478 - val_loss: 0.9170 - val_acc: 0.8480\n",
      "Epoch 32/100\n",
      "new learning rate: 0.0038152042447694616\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.5487 - acc: 0.9499 - val_loss: 0.8885 - val_acc: 0.8548\n",
      "Epoch 33/100\n",
      "new learning rate: 0.003433683820292515\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.5235 - acc: 0.9569 - val_loss: 0.8744 - val_acc: 0.8608\n",
      "Epoch 34/100\n",
      "new learning rate: 0.003090315438263264\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.5068 - acc: 0.9603 - val_loss: 0.8828 - val_acc: 0.8582\n",
      "Epoch 35/100\n",
      "new learning rate: 0.0027812838944369376\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 0.4887 - acc: 0.9631 - val_loss: 0.8846 - val_acc: 0.8590\n",
      "Epoch 36/100\n",
      "new learning rate: 0.002503155504993244\n",
      "50000/50000 [==============================] - 16s 310us/step - loss: 0.4725 - acc: 0.9674 - val_loss: 0.9023 - val_acc: 0.8618\n",
      "Epoch 37/100\n",
      "new learning rate: 0.0022528399544939196\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 0.4623 - acc: 0.9676 - val_loss: 0.8617 - val_acc: 0.8674\n",
      "Epoch 38/100\n",
      "new learning rate: 0.0020275559590445277\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.4453 - acc: 0.9724 - val_loss: 0.9262 - val_acc: 0.8604\n",
      "Epoch 39/100\n",
      "new learning rate: 0.001824800363140075\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 0.4339 - acc: 0.9740 - val_loss: 0.8661 - val_acc: 0.8716\n",
      "Epoch 40/100\n",
      "new learning rate: 0.0016423203268260676\n",
      "50000/50000 [==============================] - 16s 315us/step - loss: 0.4257 - acc: 0.9761 - val_loss: 0.8554 - val_acc: 0.8756\n",
      "Epoch 41/100\n",
      "new learning rate: 0.001478088294143461\n",
      "50000/50000 [==============================] - 16s 316us/step - loss: 0.4152 - acc: 0.9775 - val_loss: 0.8866 - val_acc: 0.8704\n",
      "Epoch 42/100\n",
      "new learning rate: 0.0013302794647291147\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.4029 - acc: 0.9811 - val_loss: 0.8725 - val_acc: 0.8766\n",
      "Epoch 43/100\n",
      "new learning rate: 0.0011972515182562034\n",
      "50000/50000 [==============================] - 16s 316us/step - loss: 0.3965 - acc: 0.9816 - val_loss: 0.8630 - val_acc: 0.8774\n",
      "Epoch 44/100\n",
      "new learning rate: 0.001077526366430583\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.3918 - acc: 0.9825 - val_loss: 0.8746 - val_acc: 0.8810\n",
      "Epoch 45/100\n",
      "new learning rate: 0.0009697737297875247\n",
      "50000/50000 [==============================] - 16s 310us/step - loss: 0.3834 - acc: 0.9847 - val_loss: 0.8869 - val_acc: 0.8766\n",
      "Epoch 46/100\n",
      "new learning rate: 0.0008727963568087723\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.3781 - acc: 0.9851 - val_loss: 0.8799 - val_acc: 0.8818\n",
      "Epoch 47/100\n",
      "new learning rate: 0.0007855167211278951\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.3757 - acc: 0.9853 - val_loss: 0.8793 - val_acc: 0.8812\n",
      "Epoch 48/100\n",
      "new learning rate: 0.0007069650490151056\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.3685 - acc: 0.9864 - val_loss: 0.8960 - val_acc: 0.8816\n",
      "Epoch 49/100\n",
      "new learning rate: 0.0006362685441135951\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 0.3656 - acc: 0.9877 - val_loss: 0.9064 - val_acc: 0.8784\n",
      "Epoch 50/100\n",
      "new learning rate: 0.0005726416897022355\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.3604 - acc: 0.9886 - val_loss: 0.9271 - val_acc: 0.8746\n",
      "Epoch 51/100\n",
      "new learning rate: 0.000515377520732012\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.3580 - acc: 0.9892 - val_loss: 0.8977 - val_acc: 0.8796\n",
      "Epoch 52/100\n",
      "new learning rate: 0.0004638397686588108\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.3533 - acc: 0.9905 - val_loss: 0.9076 - val_acc: 0.8812\n",
      "Epoch 53/100\n",
      "new learning rate: 0.0004174557917929298\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.3543 - acc: 0.9893 - val_loss: 0.9134 - val_acc: 0.8812\n",
      "Epoch 54/100\n",
      "new learning rate: 0.0003757102126136368\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.3502 - acc: 0.9903 - val_loss: 0.9079 - val_acc: 0.8792\n",
      "Epoch 55/100\n",
      "new learning rate: 0.0003381391913522731\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.3477 - acc: 0.9905 - val_loss: 0.9093 - val_acc: 0.8812\n",
      "Epoch 56/100\n",
      "new learning rate: 0.0003043252722170458\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.3452 - acc: 0.9910 - val_loss: 0.9157 - val_acc: 0.8802\n",
      "Epoch 57/100\n",
      "new learning rate: 0.0002738927449953412\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.3421 - acc: 0.9919 - val_loss: 0.9110 - val_acc: 0.8818\n",
      "Epoch 58/100\n",
      "new learning rate: 0.0002465034704958071\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 0.3428 - acc: 0.9915 - val_loss: 0.9224 - val_acc: 0.8810\n",
      "Epoch 59/100\n",
      "new learning rate: 0.0002218531234462264\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.3410 - acc: 0.9918 - val_loss: 0.9140 - val_acc: 0.8834\n",
      "Epoch 60/100\n",
      "new learning rate: 0.00019966781110160377\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.3412 - acc: 0.9917 - val_loss: 0.9199 - val_acc: 0.8810\n",
      "Epoch 61/100\n",
      "new learning rate: 0.0001797010299914434\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 0.3375 - acc: 0.9924 - val_loss: 0.9164 - val_acc: 0.8814\n",
      "Epoch 62/100\n",
      "new learning rate: 0.00016173092699229907\n",
      "50000/50000 [==============================] - 16s 315us/step - loss: 0.3375 - acc: 0.9924 - val_loss: 0.9249 - val_acc: 0.8818\n",
      "Epoch 63/100\n",
      "new learning rate: 0.00014555783429306916\n",
      "50000/50000 [==============================] - 16s 316us/step - loss: 0.3373 - acc: 0.9929 - val_loss: 0.9271 - val_acc: 0.8810\n",
      "Epoch 64/100\n",
      "new learning rate: 0.00013100205086376225\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.3358 - acc: 0.9931 - val_loss: 0.9225 - val_acc: 0.8824\n",
      "Epoch 65/100\n",
      "new learning rate: 0.00011790184577738603\n",
      "50000/50000 [==============================] - 16s 315us/step - loss: 0.3366 - acc: 0.9925 - val_loss: 0.9274 - val_acc: 0.8816\n",
      "Epoch 66/100\n",
      "new learning rate: 0.00010611166119964742\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 0.3337 - acc: 0.9934 - val_loss: 0.9262 - val_acc: 0.8808\n",
      "Epoch 67/100\n",
      "new learning rate: 9.550049507968268e-05\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.3326 - acc: 0.9935 - val_loss: 0.9279 - val_acc: 0.8810\n",
      "Epoch 68/100\n",
      "new learning rate: 8.595044557171441e-05\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 0.3325 - acc: 0.9935 - val_loss: 0.9285 - val_acc: 0.8820\n",
      "Epoch 69/100\n",
      "new learning rate: 7.735540101454298e-05\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.3330 - acc: 0.9932 - val_loss: 0.9286 - val_acc: 0.8818\n",
      "Epoch 70/100\n",
      "new learning rate: 6.961986091308867e-05\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 0.3323 - acc: 0.9937 - val_loss: 0.9286 - val_acc: 0.8822\n",
      "Epoch 71/100\n",
      "new learning rate: 6.265787482177982e-05\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.3335 - acc: 0.9929 - val_loss: 0.9288 - val_acc: 0.8826\n",
      "Epoch 72/100\n",
      "new learning rate: 5.639208733960184e-05\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 0.3316 - acc: 0.9937 - val_loss: 0.9288 - val_acc: 0.8822\n",
      "Epoch 73/100\n",
      "new learning rate: 5.0752878605641656e-05\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.3309 - acc: 0.9936 - val_loss: 0.9286 - val_acc: 0.8828\n",
      "Epoch 74/100\n",
      "new learning rate: 4.567759074507749e-05\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.3321 - acc: 0.9932 - val_loss: 0.9301 - val_acc: 0.8828\n",
      "Epoch 75/100\n",
      "new learning rate: 4.110983167056974e-05\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.3339 - acc: 0.9926 - val_loss: 0.9322 - val_acc: 0.8838\n",
      "Epoch 76/100\n",
      "new learning rate: 3.6998848503512766e-05\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.3320 - acc: 0.9936 - val_loss: 0.9309 - val_acc: 0.8828\n",
      "Epoch 77/100\n",
      "new learning rate: 3.329896365316149e-05\n",
      "50000/50000 [==============================] - 16s 310us/step - loss: 0.3304 - acc: 0.9935 - val_loss: 0.9302 - val_acc: 0.8818\n",
      "Epoch 78/100\n",
      "new learning rate: 2.996906728784534e-05\n",
      "50000/50000 [==============================] - 15s 308us/step - loss: 0.3315 - acc: 0.9934 - val_loss: 0.9325 - val_acc: 0.8806\n",
      "Epoch 79/100\n",
      "new learning rate: 2.697216055906081e-05\n",
      "50000/50000 [==============================] - 16s 310us/step - loss: 0.3318 - acc: 0.9934 - val_loss: 0.9307 - val_acc: 0.8802\n",
      "Epoch 80/100\n",
      "new learning rate: 2.427494450315473e-05\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 0.3312 - acc: 0.9931 - val_loss: 0.9289 - val_acc: 0.8814\n",
      "Epoch 81/100\n",
      "new learning rate: 2.1847450052839257e-05\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.3317 - acc: 0.9930 - val_loss: 0.9309 - val_acc: 0.8814\n",
      "Epoch 82/100\n",
      "new learning rate: 1.9662705047555334e-05\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.3295 - acc: 0.9937 - val_loss: 0.9325 - val_acc: 0.8818\n",
      "Epoch 83/100\n",
      "new learning rate: 1.76964345427998e-05\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.3307 - acc: 0.9934 - val_loss: 0.9338 - val_acc: 0.8818\n",
      "Epoch 84/100\n",
      "new learning rate: 1.592679108851982e-05\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.3309 - acc: 0.9936 - val_loss: 0.9334 - val_acc: 0.8816\n",
      "Epoch 85/100\n",
      "new learning rate: 1.4334111979667836e-05\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 0.3292 - acc: 0.9938 - val_loss: 0.9325 - val_acc: 0.8812\n",
      "Epoch 86/100\n",
      "new learning rate: 1.2900700781701055e-05\n",
      " 2048/50000 [>.............................] - ETA: 14s - loss: 0.3316 - acc: 0.9937"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-329902a3d29f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvgg16_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvgg16_trained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../weights/final/VGG16.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-12b703e861b1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                         validation_data=(x_valid, y_valid))\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mhistories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/linux/mnovak/Documents/Thesis/Code/myenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/linux/mnovak/Documents/Thesis/Code/myenv/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/linux/mnovak/Documents/Thesis/Code/myenv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/linux/mnovak/Documents/Thesis/Code/myenv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/linux/mnovak/Documents/Thesis/Code/myenv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vgg16_trained = train(clone_model(vgg16))\n",
    "vgg16_trained.save_weights('../weights/final/VGG16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "new learning rate: 0.1\n",
      "50000/50000 [==============================] - 19s 373us/step - loss: 2.1355 - acc: 0.2700 - val_loss: 8.1473 - val_acc: 0.1284\n",
      "Epoch 2/100\n",
      "new learning rate: 0.09000000000000001\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 1.6286 - acc: 0.3930 - val_loss: 2.0146 - val_acc: 0.3266\n",
      "Epoch 3/100\n",
      "new learning rate: 0.08100000000000002\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 1.4679 - acc: 0.4584 - val_loss: 1.6207 - val_acc: 0.3818\n",
      "Epoch 4/100\n",
      "new learning rate: 0.0729\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 1.3276 - acc: 0.5153 - val_loss: 1.4597 - val_acc: 0.4536\n",
      "Epoch 5/100\n",
      "new learning rate: 0.06561\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 1.1883 - acc: 0.5698 - val_loss: 1.4851 - val_acc: 0.4606\n",
      "Epoch 6/100\n",
      "new learning rate: 0.05904900000000001\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 1.0817 - acc: 0.6121 - val_loss: 1.2667 - val_acc: 0.5498\n",
      "Epoch 7/100\n",
      "new learning rate: 0.05314410000000001\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.9656 - acc: 0.6584 - val_loss: 1.2866 - val_acc: 0.5514\n",
      "Epoch 8/100\n",
      "new learning rate: 0.04782969000000001\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.8782 - acc: 0.6887 - val_loss: 1.3768 - val_acc: 0.5056\n",
      "Epoch 9/100\n",
      "new learning rate: 0.04304672100000001\n",
      "50000/50000 [==============================] - 13s 270us/step - loss: 0.7866 - acc: 0.7252 - val_loss: 1.2578 - val_acc: 0.5628\n",
      "Epoch 10/100\n",
      "new learning rate: 0.03874204890000001\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.6966 - acc: 0.7542 - val_loss: 1.1570 - val_acc: 0.6016\n",
      "Epoch 11/100\n",
      "new learning rate: 0.03486784401000001\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.6148 - acc: 0.7862 - val_loss: 1.2095 - val_acc: 0.6012\n",
      "Epoch 12/100\n",
      "new learning rate: 0.031381059609000006\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 0.5214 - acc: 0.8164 - val_loss: 1.1775 - val_acc: 0.6230\n",
      "Epoch 13/100\n",
      "new learning rate: 0.028242953648100012\n",
      "50000/50000 [==============================] - 14s 270us/step - loss: 0.4326 - acc: 0.8498 - val_loss: 1.2630 - val_acc: 0.6120\n",
      "Epoch 14/100\n",
      "new learning rate: 0.02541865828329001\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 0.3472 - acc: 0.8799 - val_loss: 1.2140 - val_acc: 0.6458\n",
      "Epoch 15/100\n",
      "new learning rate: 0.02287679245496101\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.2739 - acc: 0.9057 - val_loss: 1.2977 - val_acc: 0.6430\n",
      "Epoch 16/100\n",
      "new learning rate: 0.02058911320946491\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 0.2017 - acc: 0.9332 - val_loss: 1.3834 - val_acc: 0.6478\n",
      "Epoch 17/100\n",
      "new learning rate: 0.018530201888518418\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 0.1485 - acc: 0.9505 - val_loss: 1.6141 - val_acc: 0.6312\n",
      "Epoch 18/100\n",
      "new learning rate: 0.016677181699666577\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.1051 - acc: 0.9664 - val_loss: 1.5273 - val_acc: 0.6634\n",
      "Epoch 19/100\n",
      "new learning rate: 0.015009463529699918\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 0.0752 - acc: 0.9772 - val_loss: 1.5986 - val_acc: 0.6652\n",
      "Epoch 20/100\n",
      "new learning rate: 0.013508517176729929\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.0471 - acc: 0.9862 - val_loss: 1.5938 - val_acc: 0.6808\n",
      "Epoch 21/100\n",
      "new learning rate: 0.012157665459056936\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 0.0300 - acc: 0.9918 - val_loss: 1.5992 - val_acc: 0.6872\n",
      "Epoch 22/100\n",
      "new learning rate: 0.010941898913151242\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 0.0204 - acc: 0.9950 - val_loss: 1.6666 - val_acc: 0.6928\n",
      "Epoch 23/100\n",
      "new learning rate: 0.00984770902183612\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 0.0179 - acc: 0.9956 - val_loss: 1.6601 - val_acc: 0.6960\n",
      "Epoch 24/100\n",
      "new learning rate: 0.008862938119652507\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.0132 - acc: 0.9970 - val_loss: 1.6764 - val_acc: 0.6996\n",
      "Epoch 25/100\n",
      "new learning rate: 0.007976644307687256\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.0102 - acc: 0.9975 - val_loss: 1.6877 - val_acc: 0.7040\n",
      "Epoch 26/100\n",
      "new learning rate: 0.00717897987691853\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 0.0091 - acc: 0.9978 - val_loss: 1.7157 - val_acc: 0.7036\n",
      "Epoch 27/100\n",
      "new learning rate: 0.006461081889226678\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.0075 - acc: 0.9982 - val_loss: 1.7147 - val_acc: 0.7028\n",
      "Epoch 28/100\n",
      "new learning rate: 0.00581497370030401\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 0.0058 - acc: 0.9986 - val_loss: 1.7263 - val_acc: 0.7002\n",
      "Epoch 29/100\n",
      "new learning rate: 0.00523347633027361\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 0.0067 - acc: 0.9985 - val_loss: 1.7339 - val_acc: 0.7046\n",
      "Epoch 30/100\n",
      "new learning rate: 0.004710128697246249\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.0057 - acc: 0.9985 - val_loss: 1.7367 - val_acc: 0.7040\n",
      "Epoch 31/100\n",
      "new learning rate: 0.004239115827521624\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 0.0053 - acc: 0.9988 - val_loss: 1.7489 - val_acc: 0.7044\n",
      "Epoch 32/100\n",
      "new learning rate: 0.0038152042447694616\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.0068 - acc: 0.9983 - val_loss: 1.7572 - val_acc: 0.7052\n",
      "Epoch 33/100\n",
      "new learning rate: 0.003433683820292515\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 0.0048 - acc: 0.9990 - val_loss: 1.7545 - val_acc: 0.7022\n",
      "Epoch 34/100\n",
      "new learning rate: 0.003090315438263264\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 0.0047 - acc: 0.9989 - val_loss: 1.7610 - val_acc: 0.7036\n",
      "Epoch 35/100\n",
      "new learning rate: 0.0027812838944369376\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.0040 - acc: 0.9990 - val_loss: 1.7611 - val_acc: 0.7034\n",
      "Epoch 36/100\n",
      "new learning rate: 0.002503155504993244\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 0.0050 - acc: 0.9987 - val_loss: 1.7676 - val_acc: 0.7040\n",
      "Epoch 37/100\n",
      "new learning rate: 0.0022528399544939196\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 0.0042 - acc: 0.9990 - val_loss: 1.7704 - val_acc: 0.7050\n",
      "Epoch 38/100\n",
      "new learning rate: 0.0020275559590445277\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 0.0047 - acc: 0.9989 - val_loss: 1.7743 - val_acc: 0.7040\n",
      "Epoch 39/100\n",
      "new learning rate: 0.001824800363140075\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 0.0037 - acc: 0.9993 - val_loss: 1.7721 - val_acc: 0.7052\n",
      "Epoch 40/100\n",
      "new learning rate: 0.0016423203268260676\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 0.0034 - acc: 0.9993 - val_loss: 1.7762 - val_acc: 0.7050\n",
      "Epoch 41/100\n",
      "new learning rate: 0.001478088294143461\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 0.0034 - acc: 0.9993 - val_loss: 1.7813 - val_acc: 0.7030\n",
      "Epoch 42/100\n",
      "new learning rate: 0.0013302794647291147\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.0037 - acc: 0.9992 - val_loss: 1.7810 - val_acc: 0.7042\n",
      "Epoch 43/100\n",
      "new learning rate: 0.0011972515182562034\n",
      "50000/50000 [==============================] - 14s 270us/step - loss: 0.0031 - acc: 0.9995 - val_loss: 1.7812 - val_acc: 0.7028\n",
      "Epoch 44/100\n",
      "new learning rate: 0.001077526366430583\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 0.0037 - acc: 0.9992 - val_loss: 1.7842 - val_acc: 0.7030\n",
      "Epoch 45/100\n",
      "new learning rate: 0.0009697737297875247\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 0.0034 - acc: 0.9993 - val_loss: 1.7855 - val_acc: 0.7028\n",
      "Epoch 46/100\n",
      "new learning rate: 0.0008727963568087723\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.0034 - acc: 0.9993 - val_loss: 1.7866 - val_acc: 0.7026\n",
      "Epoch 47/100\n",
      "new learning rate: 0.0007855167211278951\n",
      "50000/50000 [==============================] - 14s 274us/step - loss: 0.0030 - acc: 0.9994 - val_loss: 1.7879 - val_acc: 0.7028\n",
      "Epoch 48/100\n",
      "new learning rate: 0.0007069650490151056\n",
      "50000/50000 [==============================] - 14s 270us/step - loss: 0.0037 - acc: 0.9992 - val_loss: 1.7908 - val_acc: 0.7030\n",
      "Epoch 49/100\n",
      "new learning rate: 0.0006362685441135951\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 0.0032 - acc: 0.9993 - val_loss: 1.7912 - val_acc: 0.7044\n",
      "Epoch 50/100\n",
      "new learning rate: 0.0005726416897022355\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 0.0028 - acc: 0.9995 - val_loss: 1.7910 - val_acc: 0.7052\n",
      "Epoch 51/100\n",
      "new learning rate: 0.000515377520732012\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 0.0046 - acc: 0.9987 - val_loss: 1.7950 - val_acc: 0.7042\n",
      "Epoch 52/100\n",
      "new learning rate: 0.0004638397686588108\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.0030 - acc: 0.9993 - val_loss: 1.7948 - val_acc: 0.7040\n",
      "Epoch 53/100\n",
      "new learning rate: 0.0004174557917929298\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.0026 - acc: 0.9996 - val_loss: 1.7952 - val_acc: 0.7034\n",
      "Epoch 54/100\n",
      "new learning rate: 0.0003757102126136368\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.0033 - acc: 0.9993 - val_loss: 1.7948 - val_acc: 0.7042\n",
      "Epoch 55/100\n",
      "new learning rate: 0.0003381391913522731\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.0034 - acc: 0.9992 - val_loss: 1.7948 - val_acc: 0.7040\n",
      "Epoch 56/100\n",
      "new learning rate: 0.0003043252722170458\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.0032 - acc: 0.9994 - val_loss: 1.7950 - val_acc: 0.7032\n",
      "Epoch 57/100\n",
      "new learning rate: 0.0002738927449953412\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 0.0031 - acc: 0.9994 - val_loss: 1.7946 - val_acc: 0.7040\n",
      "Epoch 58/100\n",
      "new learning rate: 0.0002465034704958071\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.0031 - acc: 0.9994 - val_loss: 1.7950 - val_acc: 0.7032\n",
      "Epoch 59/100\n",
      "new learning rate: 0.0002218531234462264\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 0.0027 - acc: 0.9994 - val_loss: 1.7951 - val_acc: 0.7038\n",
      "Epoch 60/100\n",
      "new learning rate: 0.00019966781110160377\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.0030 - acc: 0.9995 - val_loss: 1.7959 - val_acc: 0.7036\n",
      "Epoch 61/100\n",
      "new learning rate: 0.0001797010299914434\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 0.0027 - acc: 0.9995 - val_loss: 1.7962 - val_acc: 0.7038\n",
      "Epoch 62/100\n",
      "new learning rate: 0.00016173092699229907\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.0039 - acc: 0.9992 - val_loss: 1.7966 - val_acc: 0.7032\n",
      "Epoch 63/100\n",
      "new learning rate: 0.00014555783429306916\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 0.0028 - acc: 0.9994 - val_loss: 1.7968 - val_acc: 0.7038\n",
      "Epoch 64/100\n",
      "new learning rate: 0.00013100205086376225\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 0.0031 - acc: 0.9993 - val_loss: 1.7972 - val_acc: 0.7034\n",
      "Epoch 65/100\n",
      "new learning rate: 0.00011790184577738603\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 0.0029 - acc: 0.9994 - val_loss: 1.7968 - val_acc: 0.7032\n",
      "Epoch 66/100\n",
      "new learning rate: 0.00010611166119964742\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.0033 - acc: 0.9993 - val_loss: 1.7968 - val_acc: 0.7028\n",
      "Epoch 67/100\n",
      "new learning rate: 9.550049507968268e-05\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 0.0029 - acc: 0.9994 - val_loss: 1.7969 - val_acc: 0.7032\n",
      "Epoch 68/100\n",
      "new learning rate: 8.595044557171441e-05\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 0.0032 - acc: 0.9993 - val_loss: 1.7975 - val_acc: 0.7038\n",
      "Epoch 69/100\n",
      "new learning rate: 7.735540101454298e-05\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 0.0027 - acc: 0.9996 - val_loss: 1.7973 - val_acc: 0.7038\n",
      "Epoch 70/100\n",
      "new learning rate: 6.961986091308867e-05\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.0034 - acc: 0.9992 - val_loss: 1.7974 - val_acc: 0.7038\n",
      "Epoch 71/100\n",
      "new learning rate: 6.265787482177982e-05\n",
      "50000/50000 [==============================] - 14s 274us/step - loss: 0.0033 - acc: 0.9992 - val_loss: 1.7976 - val_acc: 0.7036\n",
      "Epoch 72/100\n",
      "new learning rate: 5.639208733960184e-05\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.0030 - acc: 0.9994 - val_loss: 1.7975 - val_acc: 0.7036\n",
      "Epoch 73/100\n",
      "new learning rate: 5.0752878605641656e-05\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.0029 - acc: 0.9995 - val_loss: 1.7975 - val_acc: 0.7030\n",
      "Epoch 74/100\n",
      "new learning rate: 4.567759074507749e-05\n",
      "50000/50000 [==============================] - 14s 274us/step - loss: 0.0030 - acc: 0.9995 - val_loss: 1.7973 - val_acc: 0.7034\n",
      "Epoch 75/100\n",
      "new learning rate: 4.110983167056974e-05\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 0.0027 - acc: 0.9995 - val_loss: 1.7976 - val_acc: 0.7032\n",
      "Epoch 76/100\n",
      "new learning rate: 3.6998848503512766e-05\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.0029 - acc: 0.9995 - val_loss: 1.7983 - val_acc: 0.7026\n",
      "Epoch 77/100\n",
      "new learning rate: 3.329896365316149e-05\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 0.0035 - acc: 0.9992 - val_loss: 1.7984 - val_acc: 0.7032\n",
      "Epoch 78/100\n",
      "new learning rate: 2.996906728784534e-05\n",
      "50000/50000 [==============================] - 13s 270us/step - loss: 0.0027 - acc: 0.9995 - val_loss: 1.7986 - val_acc: 0.7032\n",
      "Epoch 79/100\n",
      "new learning rate: 2.697216055906081e-05\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.0029 - acc: 0.9995 - val_loss: 1.7980 - val_acc: 0.7034\n",
      "Epoch 80/100\n",
      "new learning rate: 2.427494450315473e-05\n",
      "50000/50000 [==============================] - 13s 270us/step - loss: 0.0030 - acc: 0.9994 - val_loss: 1.7985 - val_acc: 0.7034\n",
      "Epoch 81/100\n",
      "new learning rate: 2.1847450052839257e-05\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.0030 - acc: 0.9993 - val_loss: 1.7985 - val_acc: 0.7032\n",
      "Epoch 82/100\n",
      "new learning rate: 1.9662705047555334e-05\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.0031 - acc: 0.9994 - val_loss: 1.7982 - val_acc: 0.7038\n",
      "Epoch 83/100\n",
      "new learning rate: 1.76964345427998e-05\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.0026 - acc: 0.9996 - val_loss: 1.7982 - val_acc: 0.7034\n",
      "Epoch 84/100\n",
      "new learning rate: 1.592679108851982e-05\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 0.0030 - acc: 0.9995 - val_loss: 1.7979 - val_acc: 0.7030\n",
      "Epoch 85/100\n",
      "new learning rate: 1.4334111979667836e-05\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 0.0028 - acc: 0.9995 - val_loss: 1.7982 - val_acc: 0.7034\n",
      "Epoch 86/100\n",
      "new learning rate: 1.2900700781701055e-05\n",
      "23552/50000 [=============>................] - ETA: 6s - loss: 0.0026 - acc: 0.9996"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f2cbe098f38f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvgg16_vanilla_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16_vanilla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvgg16_vanilla_trained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../weights/final/VGG16_Vanilla.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-12b703e861b1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                         validation_data=(x_valid, y_valid))\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mhistories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/linux/mnovak/Documents/Thesis/Code/myenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/linux/mnovak/Documents/Thesis/Code/myenv/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/linux/mnovak/Documents/Thesis/Code/myenv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/linux/mnovak/Documents/Thesis/Code/myenv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/linux/mnovak/Documents/Thesis/Code/myenv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vgg16_vanilla_trained = train(clone_model(vgg16_vanilla))\n",
    "vgg16_vanilla_trained.save_weights('../weights/final/VGG16_Vanilla.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
