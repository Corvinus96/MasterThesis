{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython extension to reload modules before executing user code.\n",
    "# 'autoreload' reloads modules automatically before entering the execution of code typed at the IPython prompt.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed initialization (for reproductible results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# Setting the seed for NumPy generated random numbers\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Setting the seed for Python random numbers\n",
    "import random as rn\n",
    "rn.seed(0)\n",
    "\n",
    "# Setting the seed for TensorFlow random numbers\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting best GPU to execute on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gpustat\n",
    "\n",
    "stats = gpustat.GPUStatCollection.new_query()\n",
    "ids = map(lambda gpu: int(gpu.entry['index']), stats)\n",
    "ratios = map(lambda gpu: float(gpu.entry['memory.used'])/float(gpu.entry['memory.total']), stats)\n",
    "bestGPU = min(zip(ids, ratios), key=lambda x: x[1])[0]\n",
    "\n",
    "print(\"setGPU: Setting GPU to: {}\".format(bestGPU))\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(bestGPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User defined packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from data_utils import import_cifar\n",
    "from models import VGG16_Vanilla, VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras.models import clone_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "weights = defaultdict(list)\n",
    "histories = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid), (x_test, y_test) = import_cifar(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 without weight decay nor dropout\n",
    "vgg16_vanilla = VGG16_Vanilla(input_shape=(32,32,3), num_classes=num_classes)\n",
    "vgg16_vanilla.save_weights(\"../weights/initial/VGG16_Vanilla.h5\")\n",
    "\n",
    "weights[vgg16_vanilla] = [[layer.get_weights() for layer in vgg16_vanilla.layers]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 with weight decay and dropout\n",
    "vgg16 = VGG16(input_shape=(32,32,3), num_classes=num_classes, weight_decay=0.005)\n",
    "vgg16.save_weights(\"../weights/initial/VGG16.h5\")\n",
    "\n",
    "weights[vgg16] = [[layer.get_weights() for layer in vgg16.layers]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    # Training parameters\n",
    "    batch_size = 1024\n",
    "    epochs = 100\n",
    "    lr = 0.1\n",
    "    \n",
    "    # Function that is going to be called after each epoch \n",
    "    # Decreases the learning rate\n",
    "    def lr_scheduler(epoch):\n",
    "        new_lr = lr * (0.9 ** epoch)\n",
    "        print('new learning rate: {}'.format(new_lr))\n",
    "        return new_lr\n",
    "    \n",
    "    reduce_lr = callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "    # Optimization details\n",
    "    sgd = optimizers.SGD(lr=lr, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(x=x_train, \n",
    "                        y=y_train, \n",
    "                        batch_size=batch_size, \n",
    "                        epochs=epochs, \n",
    "                        verbose=1, \n",
    "                        callbacks=[EarlyStopping(monitor='val_loss', patience=5), reduce_lr],  \n",
    "                        validation_data=(x_valid, y_valid))\n",
    "    \n",
    "    histories[model].append(history)\n",
    "    weights[model].append([layer.get_weights() for layer in model.layers])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "new learning rate: 0.1\n",
      "50000/50000 [==============================] - 28s 554us/step - loss: 35.1959 - acc: 0.1914 - val_loss: 28.8257 - val_acc: 0.1202\n",
      "Epoch 2/100\n",
      "new learning rate: 0.09000000000000001\n",
      "50000/50000 [==============================] - 15s 307us/step - loss: 18.5247 - acc: 0.3261 - val_loss: 12.7944 - val_acc: 0.0974\n",
      "Epoch 3/100\n",
      "new learning rate: 0.08100000000000002\n",
      "50000/50000 [==============================] - 15s 304us/step - loss: 8.6139 - acc: 0.3659 - val_loss: 6.7672 - val_acc: 0.1070\n",
      "Epoch 4/100\n",
      "new learning rate: 0.0729\n",
      "50000/50000 [==============================] - 15s 303us/step - loss: 4.6721 - acc: 0.4703 - val_loss: 4.5564 - val_acc: 0.0998\n",
      "Epoch 5/100\n",
      "new learning rate: 0.06561\n",
      "50000/50000 [==============================] - 15s 308us/step - loss: 3.0568 - acc: 0.5393 - val_loss: 3.7510 - val_acc: 0.0994\n",
      "Epoch 6/100\n",
      "new learning rate: 0.05904900000000001\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 2.6429 - acc: 0.5398 - val_loss: 4.7847 - val_acc: 0.1304\n",
      "Epoch 7/100\n",
      "new learning rate: 0.05314410000000001\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 2.1633 - acc: 0.6342 - val_loss: 3.2589 - val_acc: 0.1282\n",
      "Epoch 8/100\n",
      "new learning rate: 0.04782969000000001\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 2.0208 - acc: 0.6582 - val_loss: 3.4930 - val_acc: 0.1060\n",
      "Epoch 9/100\n",
      "new learning rate: 0.04304672100000001\n",
      "50000/50000 [==============================] - 16s 310us/step - loss: 1.8089 - acc: 0.7180 - val_loss: 3.3213 - val_acc: 0.1134\n",
      "Epoch 10/100\n",
      "new learning rate: 0.03874204890000001\n",
      "50000/50000 [==============================] - 16s 310us/step - loss: 1.6076 - acc: 0.7331 - val_loss: 3.1153 - val_acc: 0.2106\n",
      "Epoch 11/100\n",
      "new learning rate: 0.03486784401000001\n",
      "50000/50000 [==============================] - 16s 317us/step - loss: 1.6553 - acc: 0.7219 - val_loss: 2.6264 - val_acc: 0.4284\n",
      "Epoch 12/100\n",
      "new learning rate: 0.031381059609000006\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 1.4914 - acc: 0.7669 - val_loss: 2.6083 - val_acc: 0.3684\n",
      "Epoch 13/100\n",
      "new learning rate: 0.028242953648100012\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 1.6410 - acc: 0.7425 - val_loss: 2.7797 - val_acc: 0.3568\n",
      "Epoch 14/100\n",
      "new learning rate: 0.02541865828329001\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 1.5305 - acc: 0.7812 - val_loss: 2.0361 - val_acc: 0.6312\n",
      "Epoch 15/100\n",
      "new learning rate: 0.02287679245496101\n",
      "50000/50000 [==============================] - 16s 310us/step - loss: 1.4507 - acc: 0.7873 - val_loss: 1.7887 - val_acc: 0.6940\n",
      "Epoch 16/100\n",
      "new learning rate: 0.02058911320946491\n",
      "50000/50000 [==============================] - 16s 317us/step - loss: 1.3488 - acc: 0.8050 - val_loss: 1.7334 - val_acc: 0.6900\n",
      "Epoch 17/100\n",
      "new learning rate: 0.018530201888518418\n",
      "50000/50000 [==============================] - 15s 308us/step - loss: 1.3193 - acc: 0.8074 - val_loss: 1.7830 - val_acc: 0.6402\n",
      "Epoch 18/100\n",
      "new learning rate: 0.016677181699666577\n",
      "50000/50000 [==============================] - 16s 310us/step - loss: 1.1988 - acc: 0.8327 - val_loss: 1.6467 - val_acc: 0.6906\n",
      "Epoch 19/100\n",
      "new learning rate: 0.015009463529699918\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 1.1793 - acc: 0.8316 - val_loss: 1.6515 - val_acc: 0.6798\n",
      "Epoch 20/100\n",
      "new learning rate: 0.013508517176729929\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 1.1013 - acc: 0.8472 - val_loss: 1.4449 - val_acc: 0.7232\n",
      "Epoch 21/100\n",
      "new learning rate: 0.012157665459056936\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.9856 - acc: 0.8693 - val_loss: 1.4211 - val_acc: 0.7260\n",
      "Epoch 22/100\n",
      "new learning rate: 0.010941898913151242\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.9083 - acc: 0.8841 - val_loss: 1.3542 - val_acc: 0.7380\n",
      "Epoch 23/100\n",
      "new learning rate: 0.00984770902183612\n",
      "50000/50000 [==============================] - 16s 310us/step - loss: 0.8546 - acc: 0.8917 - val_loss: 1.3642 - val_acc: 0.7290\n",
      "Epoch 24/100\n",
      "new learning rate: 0.008862938119652507\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.8034 - acc: 0.9000 - val_loss: 1.1181 - val_acc: 0.7928\n",
      "Epoch 25/100\n",
      "new learning rate: 0.007976644307687256\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 0.7570 - acc: 0.9092 - val_loss: 1.1556 - val_acc: 0.7846\n",
      "Epoch 26/100\n",
      "new learning rate: 0.00717897987691853\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.7170 - acc: 0.9177 - val_loss: 1.1691 - val_acc: 0.7732\n",
      "Epoch 27/100\n",
      "new learning rate: 0.006461081889226678\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 0.6910 - acc: 0.9213 - val_loss: 0.9783 - val_acc: 0.8290\n",
      "Epoch 28/100\n",
      "new learning rate: 0.00581497370030401\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.6560 - acc: 0.9308 - val_loss: 0.9404 - val_acc: 0.8386\n",
      "Epoch 29/100\n",
      "new learning rate: 0.00523347633027361\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.6210 - acc: 0.9358 - val_loss: 0.9566 - val_acc: 0.8374\n",
      "Epoch 30/100\n",
      "new learning rate: 0.004710128697246249\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.5980 - acc: 0.9427 - val_loss: 0.9183 - val_acc: 0.8458\n",
      "Epoch 31/100\n",
      "new learning rate: 0.004239115827521624\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 0.5770 - acc: 0.9466 - val_loss: 0.9424 - val_acc: 0.8416\n",
      "Epoch 32/100\n",
      "new learning rate: 0.0038152042447694616\n",
      "50000/50000 [==============================] - 16s 310us/step - loss: 0.5529 - acc: 0.9508 - val_loss: 0.9140 - val_acc: 0.8506\n",
      "Epoch 33/100\n",
      "new learning rate: 0.003433683820292515\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.5320 - acc: 0.9548 - val_loss: 0.8863 - val_acc: 0.8602\n",
      "Epoch 34/100\n",
      "new learning rate: 0.003090315438263264\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.5141 - acc: 0.9595 - val_loss: 0.8936 - val_acc: 0.8574\n",
      "Epoch 35/100\n",
      "new learning rate: 0.0027812838944369376\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 0.4968 - acc: 0.9628 - val_loss: 0.8822 - val_acc: 0.8668\n",
      "Epoch 36/100\n",
      "new learning rate: 0.002503155504993244\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.4808 - acc: 0.9660 - val_loss: 0.8995 - val_acc: 0.8676\n",
      "Epoch 37/100\n",
      "new learning rate: 0.0022528399544939196\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 0.4627 - acc: 0.9708 - val_loss: 0.8774 - val_acc: 0.8624\n",
      "Epoch 38/100\n",
      "new learning rate: 0.0020275559590445277\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.4560 - acc: 0.9712 - val_loss: 0.8867 - val_acc: 0.8704\n",
      "Epoch 39/100\n",
      "new learning rate: 0.001824800363140075\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.4380 - acc: 0.9753 - val_loss: 0.8945 - val_acc: 0.8718\n",
      "Epoch 40/100\n",
      "new learning rate: 0.0016423203268260676\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.4319 - acc: 0.9765 - val_loss: 0.8964 - val_acc: 0.8712\n",
      "Epoch 41/100\n",
      "new learning rate: 0.001478088294143461\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.4224 - acc: 0.9784 - val_loss: 0.9182 - val_acc: 0.8676\n",
      "Epoch 42/100\n",
      "new learning rate: 0.0013302794647291147\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 0.4111 - acc: 0.9805 - val_loss: 0.9070 - val_acc: 0.8728\n"
     ]
    }
   ],
   "source": [
    "vgg16_trained = train(clone_model(vgg16))\n",
    "vgg16_trained.save_weights('../weights/final/VGG16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "new learning rate: 0.1\n",
      "50000/50000 [==============================] - 18s 356us/step - loss: 2.1801 - acc: 0.2652 - val_loss: 7.7788 - val_acc: 0.1458\n",
      "Epoch 2/100\n",
      "new learning rate: 0.09000000000000001\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 1.6073 - acc: 0.4075 - val_loss: 1.7951 - val_acc: 0.3758\n",
      "Epoch 3/100\n",
      "new learning rate: 0.08100000000000002\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 1.4169 - acc: 0.4823 - val_loss: 1.5939 - val_acc: 0.4136\n",
      "Epoch 4/100\n",
      "new learning rate: 0.0729\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 1.2836 - acc: 0.5356 - val_loss: 1.5535 - val_acc: 0.4290\n",
      "Epoch 5/100\n",
      "new learning rate: 0.06561\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 1.1735 - acc: 0.5792 - val_loss: 1.3795 - val_acc: 0.4958\n",
      "Epoch 6/100\n",
      "new learning rate: 0.05904900000000001\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 1.0714 - acc: 0.6171 - val_loss: 1.3341 - val_acc: 0.5090\n",
      "Epoch 7/100\n",
      "new learning rate: 0.05314410000000001\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 0.9804 - acc: 0.6535 - val_loss: 1.2537 - val_acc: 0.5452\n",
      "Epoch 8/100\n",
      "new learning rate: 0.04782969000000001\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 0.9044 - acc: 0.6811 - val_loss: 1.1911 - val_acc: 0.5672\n",
      "Epoch 9/100\n",
      "new learning rate: 0.04304672100000001\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.8247 - acc: 0.7085 - val_loss: 1.0892 - val_acc: 0.6148\n",
      "Epoch 10/100\n",
      "new learning rate: 0.03874204890000001\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.7646 - acc: 0.7317 - val_loss: 1.0642 - val_acc: 0.6318\n",
      "Epoch 11/100\n",
      "new learning rate: 0.03486784401000001\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 0.6818 - acc: 0.7593 - val_loss: 1.0900 - val_acc: 0.6130\n",
      "Epoch 12/100\n",
      "new learning rate: 0.031381059609000006\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 0.6028 - acc: 0.7881 - val_loss: 1.0239 - val_acc: 0.6492\n",
      "Epoch 13/100\n",
      "new learning rate: 0.028242953648100012\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 0.5458 - acc: 0.8095 - val_loss: 1.0182 - val_acc: 0.6442\n",
      "Epoch 14/100\n",
      "new learning rate: 0.02541865828329001\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 0.4681 - acc: 0.8373 - val_loss: 1.1101 - val_acc: 0.6312\n",
      "Epoch 15/100\n",
      "new learning rate: 0.02287679245496101\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.3927 - acc: 0.8649 - val_loss: 1.2130 - val_acc: 0.6274\n",
      "Epoch 16/100\n",
      "new learning rate: 0.02058911320946491\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 0.3232 - acc: 0.8903 - val_loss: 1.1671 - val_acc: 0.6592\n",
      "Epoch 17/100\n",
      "new learning rate: 0.018530201888518418\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 0.2589 - acc: 0.9115 - val_loss: 1.2476 - val_acc: 0.6500\n",
      "Epoch 18/100\n",
      "new learning rate: 0.016677181699666577\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 0.2059 - acc: 0.9316 - val_loss: 1.3711 - val_acc: 0.6450\n"
     ]
    }
   ],
   "source": [
    "vgg16_vanilla_trained = train(clone_model(vgg16_vanilla))\n",
    "vgg16_vanilla_trained.save_weights('../weights/final/VGG16_Vanilla.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
