{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#IPython extension to reload modules before executing user code.\n",
    "#'autoreload' reloads modules automatically before entering the execution of code typed at the IPython prompt.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "import gpustat\n",
    "\n",
    "#select the best free GPU on the nvidia card\n",
    "stats = gpustat.GPUStatCollection.new_query()\n",
    "ids = map(lambda gpu: int(gpu.entry['index']), stats)\n",
    "ratios = map(lambda gpu: float(gpu.entry['memory.used'])/float(gpu.entry['memory.total']), stats)\n",
    "bestGPU = min(zip(ids, ratios), key=lambda x: x[1])[0]\n",
    "bestGPU = 3\n",
    "\n",
    "print(\"setGPU: Setting GPU to: {}\".format(bestGPU))\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(bestGPU)\n",
    "\n",
    "\n",
    "#set memory usage to 0.5\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q keract \n",
    "import collections\n",
    "import numpy\n",
    "import mutual_info\n",
    "from keract import get_activations, display_activations\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import optimizers, regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.datasets import cifar10 # we can use also cifar100\n",
    "from keras.layers import Input, BatchNormalization, AveragePooling2D, ZeroPadding2D, LeakyReLU, GlobalAveragePooling2D, Dense, Flatten, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import time\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import of the models\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "from models import VGG16, VGG16_Vanilla, VGG16_beta,VGG16_Vanilla_beta\n",
    "from data_utils import import_cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATABase\n",
    "num_classes = 10\n",
    "(x_train, y_train), (x_test, y_test) = import_cifar(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD huge MODELS\n",
    "modelB = VGG16_Vanilla_beta(input_shape=(32,32,3), num_classes=10) #without Weight Decay but batchNorm before activation\n",
    "modelC = VGG16_beta(input_shape=(32,32,3), num_classes=10, weight_decay=0.005) #with Weight Decay, and batchNorm before activation\n",
    "modelD = VGG16_Vanilla_beta(input_shape=(32,32,3), num_classes=10) #without Weight Decay, but batchNorm before activation and with layca\n",
    "modelE = VGG16_Vanilla_beta(input_shape=(32,32,3), num_classes=10) #with layca but with a bad LR\n",
    "\n",
    "modelB.load_weights(\"../weights/1/vgg16_vanilla_beta/final/weights-final.hdf5\")\n",
    "modelC.load_weights(\"../weights/1/vgg16_beta/final/weights-final.hdf5\")\n",
    "modelD.load_weights(\"../weights/1/vgg16_vanilla_layca/final/weights-final.hdf5\")\n",
    "modelE.load_weights(\"../weights/2/vgg16_vanilla_layca_bad/final/weights-final.hdf5\")\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.2, momentum=0.9, nesterov=True)\n",
    "modelB.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "modelC.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "modelD.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "modelE.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_of_Layers = [[\n",
    "'conv2d_1/BiasAdd:0', \n",
    "'conv2d_2/BiasAdd:0',\n",
    "'max_pooling2d_1/MaxPool:0',\n",
    "'conv2d_3/BiasAdd:0', \n",
    "'conv2d_4/BiasAdd:0', \n",
    "'max_pooling2d_2/MaxPool:0',\n",
    "'conv2d_5/BiasAdd:0', \n",
    "'conv2d_6/BiasAdd:0',  \n",
    "'conv2d_7/BiasAdd:0', \n",
    "'max_pooling2d_3/MaxPool:0', \n",
    "'conv2d_8/BiasAdd:0',  \n",
    "'conv2d_9/BiasAdd:0', \n",
    "'conv2d_10/BiasAdd:0', \n",
    "'max_pooling2d_4/MaxPool:0', \n",
    "'conv2d_11/BiasAdd:0',    \n",
    "'conv2d_12/BiasAdd:0',\n",
    "'conv2d_13/BiasAdd:0', \n",
    "'max_pooling2d_5/MaxPool:0', \n",
    "'dense_1/BiasAdd:0', \n",
    "'dense_2/BiasAdd:0', \n",
    " ], [\n",
    "'conv2d_14/BiasAdd:0', \n",
    "'conv2d_15/BiasAdd:0',\n",
    "'max_pooling2d_6/MaxPool:0',\n",
    "'conv2d_16/BiasAdd:0', \n",
    "'conv2d_17/BiasAdd:0', \n",
    "'max_pooling2d_7/MaxPool:0',\n",
    "'conv2d_18/BiasAdd:0', \n",
    "'conv2d_19/BiasAdd:0',  \n",
    "'conv2d_20/BiasAdd:0', \n",
    "'max_pooling2d_8/MaxPool:0', \n",
    "'conv2d_21/BiasAdd:0',  \n",
    "'conv2d_22/BiasAdd:0', \n",
    "'conv2d_23/BiasAdd:0', \n",
    "'max_pooling2d_9/MaxPool:0', \n",
    "'conv2d_24/BiasAdd:0',    \n",
    "'conv2d_25/BiasAdd:0',\n",
    "'conv2d_26/BiasAdd:0', \n",
    "'max_pooling2d_10/MaxPool:0', \n",
    "'dense_3/BiasAdd:0', \n",
    "'dense_4/BiasAdd:0', \n",
    " ], [\n",
    "'conv2d_27/BiasAdd:0', \n",
    "'conv2d_28/BiasAdd:0',\n",
    "'max_pooling2d_11/MaxPool:0',\n",
    "'conv2d_29/BiasAdd:0', \n",
    "'conv2d_30/BiasAdd:0', \n",
    "'max_pooling2d_12/MaxPool:0',\n",
    "'conv2d_31/BiasAdd:0', \n",
    "'conv2d_32/BiasAdd:0',  \n",
    "'conv2d_33/BiasAdd:0', \n",
    "'max_pooling2d_13/MaxPool:0', \n",
    "'conv2d_34/BiasAdd:0',  \n",
    "'conv2d_35/BiasAdd:0', \n",
    "'conv2d_36/BiasAdd:0', \n",
    "'max_pooling2d_14/MaxPool:0', \n",
    "'conv2d_37/BiasAdd:0',    \n",
    "'conv2d_38/BiasAdd:0',\n",
    "'conv2d_39/BiasAdd:0', \n",
    "'max_pooling2d_15/MaxPool:0', \n",
    "'dense_5/BiasAdd:0', \n",
    "'dense_6/BiasAdd:0', \n",
    " ], [\n",
    "'conv2d_40/BiasAdd:0', \n",
    "'conv2d_41/BiasAdd:0',\n",
    "'max_pooling2d_16/MaxPool:0',\n",
    "'conv2d_42/BiasAdd:0', \n",
    "'conv2d_43/BiasAdd:0', \n",
    "'max_pooling2d_17/MaxPool:0',\n",
    "'conv2d_44/BiasAdd:0', \n",
    "'conv2d_45/BiasAdd:0',  \n",
    "'conv2d_46/BiasAdd:0', \n",
    "'max_pooling2d_18/MaxPool:0', \n",
    "'conv2d_47/BiasAdd:0',  \n",
    "'conv2d_48/BiasAdd:0', \n",
    "'conv2d_49/BiasAdd:0', \n",
    "'max_pooling2d_19/MaxPool:0', \n",
    "'conv2d_50/BiasAdd:0',    \n",
    "'conv2d_51/BiasAdd:0',\n",
    "'conv2d_52/BiasAdd:0', \n",
    "'max_pooling2d_20/MaxPool:0', \n",
    "'dense_7/BiasAdd:0', \n",
    "'dense_8/BiasAdd:0', \n",
    " ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EVALUATION\n",
    "# Final evaluation of the models\n",
    "scoresB = modelB.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scoresB[0])\n",
    "print('Test accuracy:', scoresB[1])\n",
    "print(\"%.2f%% : Model B without Weightdecay with BatchNorm before activation CNN Error\" % (100-scoresB[1]*100))\n",
    "scoresC = modelC.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scoresC[0])\n",
    "print('Test accuracy:', scoresC[1])\n",
    "print(\"%.2f%% : Model C with Weightdecay Error\" % (100-scoresC[1]*100))\n",
    "scoresD = modelD.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scoresD[0])\n",
    "print('Test accuracy:', scoresD[1])\n",
    "print(\"%.2f%% : Model D with layca Error\"  % (100-scoresD[1]*100))\n",
    "scoresE = modelE.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scoresE[0])\n",
    "print('Test accuracy:', scoresE[1])\n",
    "print(\"%.2f%% : Model E with layca with bad LR Error\" % (100-scoresE[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information\n",
    "On regarde l'information mutuelle arrondie à des binaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regarde l'activation des pairs de neurones pour un echantillon test pris au hasard\n",
    "Echantillon = []\n",
    "nombreDImagesDActivation = 50\n",
    "NombrePairs = 1000#0\n",
    "choix = numpy.random.choice(x_test.shape[0], nombreDImagesDActivation)\n",
    "Echantillon = x_test[choix, :, : , :]\n",
    "\n",
    "#Echantillon = [x_test[0], x_test[1], x_test[2], x_test[3], x_test[4], x_test[5], x_test[6], x_test[7], x_test[8], x_test[9], x_test[10], x_test[11], x_test[12], x_test[13]]\n",
    "IMB = get_activations(modelB, Echantillon)\n",
    "IMC = get_activations(modelC, Echantillon)\n",
    "IMD = get_activations(modelD, Echantillon)\n",
    "IME = get_activations(modelE, Echantillon)\n",
    "# on affiche les noms des differentes couches\n",
    "#print(IMA.keys())\n",
    "#modelA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MI():\n",
    "    M = []\n",
    "    number_of_models = 4\n",
    "    for i in range(number_of_models):\n",
    "        for layer in List_of_Layers[i]:\n",
    "            print(layer)\n",
    "            print(i)\n",
    "    '''\n",
    "    #count of the number of MI = 1\n",
    "    CountMI1 = 0\n",
    "    #count the number of pathologic neurons (only 1 or 0)\n",
    "    pathologicCount = 0\n",
    "    pathologicCount_00 = 0\n",
    "    pathologicCount_01 = 0\n",
    "    pathologicCount_11 = 0\n",
    "    MutualInfoWithoutOnes = []\n",
    "    \n",
    "    #nombre d'images utilisées pour l'activation:\n",
    "    numActivations = len(IM[nameOfTheLayer])\n",
    "    \n",
    "    #nombre de neurones dans la couche\n",
    "    #numNeurons = len(IM[nameOfTheLayer][0])\n",
    "    numNeurons = numpy.size(IM[nameOfTheLayer][0])\n",
    "    print('number of neurons for the layer: '+str(numNeurons))\n",
    "\n",
    "    #print(IM[nameOfTheLayer])\n",
    "    #plt.imshow(IM[nameOfTheLayer])\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "    # on selectionne des pair de neurones (X,Y) à comparer (regarder l'information mutuelle entre X et Y)\n",
    "    NeuronsSelected = numpy.zeros((NombrePairs,2))  # initialize\n",
    "\n",
    "    for i in range(NombrePairs):\n",
    "        NeuronsSelected[i] = numpy.ceil(numpy.random.rand(2)*numNeurons)  # on prend 2 neurones selectionnées aleatoirement\n",
    "        # les 2 neurones doivent être différents\n",
    "        while NeuronsSelected[i][0] == NeuronsSelected[i][1]:\n",
    "            NeuronsSelected[i] = numpy.ceil(numpy.random.rand(2)*numNeurons)\n",
    "\n",
    "    #print(NeuronsSelected[56])\n",
    "    #print(NeuronsSelected[56][0])\n",
    "    \n",
    "    MutualInfo = numpy.zeros((NombrePairs,1))  # initialization des resultats\n",
    "\n",
    "    for j in range(NombrePairs):\n",
    "        X = numpy.zeros((numActivations,1))  # initialization du vecteur X\n",
    "        Y = numpy.zeros((numActivations,1))  # initialization du vecteur y\n",
    "\n",
    "        i = 0\n",
    "        for activation in IM[nameOfTheLayer]:   # pour chaque element de l'echantillon (= chaque activation)\n",
    "            #print(activation)\n",
    "            #print(numpy.size(activation))\n",
    "            activation = activation.flatten()\n",
    "            #print(activation)\n",
    "            \n",
    "            #on normalise les acrtivations\n",
    "            NormedActivation = activation / numpy.linalg.norm(activation)\n",
    "            \n",
    "            X[i] = NormedActivation[int(NeuronsSelected[j][0])-1] # on regarde l'activation du neurone selectionné\n",
    "            Y[i] = NormedActivation[int(NeuronsSelected[j][1])-1]\n",
    "            \n",
    "            # on binarise a la moyenne des activations:\n",
    "            Val_Binarization_X = numpy.mean(X)\n",
    "            Val_Binarization_Y = numpy.mean(Y)\n",
    "            \n",
    "            \n",
    "            if X[i] > Val_Binarization_X:\n",
    "                X[i] = 1\n",
    "            else:\n",
    "                X[i] = 0\n",
    "            if Y[i] > Val_Binarization_Y:\n",
    "                Y[i] = 1\n",
    "            else:\n",
    "                Y[i] = 0\n",
    "\n",
    "            i = i+1\n",
    "\n",
    "        X = X.flatten()\n",
    "        Y = Y.flatten()\n",
    "        print(entropy(X))\n",
    "        print(entropy(Y))\n",
    "\n",
    "        # example:= sklearn.metrics.normalized_mutual_info_score([1.1,1.0,1.0,1.0,0.0],[1.1,0.1,0.1,1.1,0.1])\n",
    "        MutualInfo[j] = sklearn.metrics.normalized_mutual_info_score(X,Y,average_method='max')\n",
    "        #print(MutualInfo[j])\n",
    "        \n",
    "        # on capte les neurones pathologiques\n",
    "        if (MutualInfo[j])==1.:\n",
    "            CountMI1 = CountMI1 + 1\n",
    "            if all([ v == 0 for v in X ]) and all([ v == 0 for v in Y ]):\n",
    "                pathologicCount = pathologicCount + 1\n",
    "                pathologicCount_00 = pathologicCount_00 + 1\n",
    "            elif all([ v == 1 for v in X ]) and all([ v == 1 for v in Y ]):\n",
    "                pathologicCount = pathologicCount + 1\n",
    "                pathologicCount_11 = pathologicCount_11 + 1\n",
    "            elif all([ v == 0 for v in X ]) and all([ v == 1 for v in Y ]):\n",
    "                pathologicCount = pathologicCount + 1\n",
    "                pathologicCount_01 = pathologicCount_01 + 1\n",
    "            elif all([ v == 1 for v in X ]) and all([ v == 0 for v in Y ]):\n",
    "                pathologicCount = pathologicCount + 1\n",
    "                pathologicCount_01 = pathologicCount_01 + 1\n",
    "        else:\n",
    "            MutualInfoWithoutOnes.append(MutualInfo[j])\n",
    "            \n",
    "    return MutualInfo, MutualInfoWithoutOnes, CountMI1, pathologicCount, pathologicCount_00, pathologicCount_11, pathologicCount_01\n",
    "    '''\n",
    "    return M        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MI(IME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of variables for the plots\n",
    "MIMeanE = []\n",
    "MI_1MeanE = []\n",
    "PCountE = []\n",
    "PCountE_0 = []\n",
    "PCountE_1 = []\n",
    "PCountE_M = []\n",
    "VarPathE = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images used for see the activations : 50\n",
      "\n",
      "number of pairs of neurons analyzed: 1000\n",
      "\n",
      " Model E :\n",
      "\n",
      "couche : conv2d_40/BiasAdd:0\n",
      "number of neurons for the layer: 65536\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nearest_distances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-d63b86e48ba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'couche :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#MI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mMutualInfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMutualInfoWithoutOnes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCountMI1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathologicCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathologicCount_00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathologicCount_11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathologicCount_01\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mMIMeanE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMutualInfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mMI_1MeanE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMutualInfoWithoutOnes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-23e740d4d214>\u001b[0m in \u001b[0;36mMI\u001b[0;34m(IM, nameOfTheLayer)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/linux/mnovak/Documents/Thesis/Code/Analysis of layer redundancy/entropy.py\u001b[0m in \u001b[0;36mentropy\u001b[0;34m(X, k)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nearest_distances' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x7200 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('number of images used for see the activations : '+str(nombreDImagesDActivation) + '\\n')\n",
    "print('number of pairs of neurons analyzed: '+str(NombrePairs))\n",
    "\n",
    "fig = plt.figure(figsize=(12, 100))\n",
    "i = 1\n",
    "print('\\n Model E :\\n')\n",
    "for layer in List_of_Layers_E:\n",
    "    plt.subplot(len(List_of_Layers_E), 1 ,i)\n",
    "    #nom de la couche\n",
    "    print('couche :', str(layer))\n",
    "    #MI\n",
    "    MutualInfo, MutualInfoWithoutOnes, CountMI1, pathologicCount, pathologicCount_00, pathologicCount_11, pathologicCount_01 = MI(IME, layer)\n",
    "    MIMeanE.append(numpy.mean(MutualInfo))\n",
    "    MI_1MeanE.append(numpy.mean(MutualInfoWithoutOnes))\n",
    "    PCountE.append(pathologicCount)\n",
    "    PCountE_0.append(pathologicCount_00)\n",
    "    PCountE_1.append(pathologicCount_11)\n",
    "    PCountE_M.append(pathologicCount_01)\n",
    "    #plot\n",
    "    plt.hist(MutualInfo, range = (0, 1.001), bins = 100, color = 'yellow',\n",
    "            edgecolor = 'red')\n",
    "    plt.xlabel('Mutual Information')\n",
    "    plt.ylabel('Occurence')\n",
    "    plt.title('\\n Occurence de la mutual information de '+str(nombreDImagesDActivation)+' images d\\'activation\\n Sur '+str(NombrePairs)+' pairs de neurones pris aléatoirement\\n sur la couche: '+ str(layer)+' du modele A : without WD')\n",
    "    plt.tight_layout()\n",
    "    plt.ylim(top=NombrePairs)\n",
    "    plt.axvline(x=MIMeanE[-1], color='red')\n",
    "    plt.axvline(x=MI_1MeanE[-1], color='blue')\n",
    "    print('MI mean: ', str(MIMeanE[-1]))\n",
    "    print('MI without_1 mean: ', str(MI_1MeanE[-1]))\n",
    "    print('pathologic pair Count: ', str(pathologicCount),' on ',str(NombrePairs),' pairs = ',str(pathologicCount/NombrePairs*100),'%')\n",
    "    print('pathologic pair Count: ', str(pathologicCount),'->  pathologic Count 0: ',str(pathologicCount_00),'  pathologic Count 1: ',str(pathologicCount_11),'  pathologic Count mix: ', str(pathologicCount_01))\n",
    "    if CountMI1 != 0:\n",
    "        VarPathE.append(pathologicCount/CountMI1)\n",
    "    else:\n",
    "        VarPathE.append(0)\n",
    "    print('pathologic pair Count: ', str(pathologicCount),' on ',str(CountMI1),' MI1 = ',str(VarPathE[-1]*100),'%')\n",
    "    print('\\n')\n",
    "    i = i+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
