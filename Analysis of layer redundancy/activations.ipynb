{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gpustat\n",
    "\n",
    "stats = gpustat.GPUStatCollection.new_query()\n",
    "ids = map(lambda gpu: int(gpu.entry['index']), stats)\n",
    "ratios = map(lambda gpu: float(gpu.entry['memory.used'])/float(gpu.entry['memory.total']), stats)\n",
    "bestGPU = min(zip(ids, ratios), key=lambda x: x[1])[0]\n",
    "\n",
    "print(\"setGPU: Setting GPU to: {}\".format(bestGPU))\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(bestGPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# IMPORT\n",
    "import numpy\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.datasets import cifar10 # we can use also cifar100\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "\n",
    "#print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "num_classes = 10\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q keract \n",
    "from keract import get_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MODELS\n",
    "model0 = load_model('models/model0.h5')\n",
    "model0.load_weights('models/model0_weights25.h5')\n",
    "model1 = load_model('models/model1.h5')\n",
    "model1.load_weights('models/model1_weights25.h5')\n",
    "model2 = load_model('models/model2.h5')\n",
    "model2.load_weights('models/model2_weights25.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 176us/step\n",
      "Test loss: 0.7553634172439575\n",
      "Test accuracy: 0.7527\n",
      "Model 1 CNN Error: 24.73%\n",
      "10000/10000 [==============================] - 1s 73us/step\n",
      "Test loss: 1.7675633235931396\n",
      "Test accuracy: 0.3616\n",
      "Model 1 CNN Error: 63.84%\n",
      "10000/10000 [==============================] - 1s 74us/step\n",
      "Test loss: 1.356453879547119\n",
      "Test accuracy: 0.5082\n",
      "Model 2 Error: 49.18%\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION\n",
    "# Final evaluation of the models\n",
    "scores0 = model0.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores0[0])\n",
    "print('Test accuracy:', scores0[1])\n",
    "print(\"Model 1 CNN Error: %.2f%%\" % (100-scores0[1]*100))\n",
    "scores1 = model1.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores1[0])\n",
    "print('Test accuracy:', scores1[1])\n",
    "print(\"Model 1 CNN Error: %.2f%%\" % (100-scores1[1]*100))\n",
    "scores2 = model2.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores2[0])\n",
    "print('Test accuracy:', scores2[1])\n",
    "print(\"Model 2 Error: %.2f%%\" % (100-scores2[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTIVATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual information\n",
    "\n",
    "Regarder l'information mutuelle AVEC DES INT #binaires (! restriction d'arrondi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['activation_4/Relu:0', 'max_pooling2d_1/MaxPool:0', 'activation_3/Relu:0', 'dropout_2/cond/Merge:0', 'dense_1/BiasAdd:0', 'conv2d_4/BiasAdd:0', 'activation_6/Softmax:0', 'max_pooling2d_2/MaxPool:0', 'conv2d_3/BiasAdd:0', 'conv2d_2/BiasAdd:0', 'conv2d_1/BiasAdd:0', 'dropout_3/cond/Merge:0', 'activation_1/Relu:0', 'activation_5/Relu:0', 'activation_2/Relu:0', 'flatten_1/Reshape:0', 'dropout_1/cond/Merge:0', 'dense_2/BiasAdd:0'])\n",
      "dict_keys(['activation_4/Relu:0', 'max_pooling2d_1/MaxPool:0', 'activation_3/Relu:0', 'dropout_2/cond/Merge:0', 'dense_1/BiasAdd:0', 'conv2d_4/BiasAdd:0', 'activation_6/Softmax:0', 'max_pooling2d_2/MaxPool:0', 'conv2d_3/BiasAdd:0', 'conv2d_2/BiasAdd:0', 'conv2d_1/BiasAdd:0', 'dropout_3/cond/Merge:0', 'activation_1/Relu:0', 'activation_5/Relu:0', 'activation_2/Relu:0', 'flatten_1/Reshape:0', 'dropout_1/cond/Merge:0', 'dense_2/BiasAdd:0'])\n",
      "dict_keys(['activation_4/Relu:0', 'max_pooling2d_1/MaxPool:0', 'activation_3/Relu:0', 'dropout_2/cond/Merge:0', 'dense_1/BiasAdd:0', 'conv2d_4/BiasAdd:0', 'activation_6/Softmax:0', 'max_pooling2d_2/MaxPool:0', 'conv2d_3/BiasAdd:0', 'conv2d_2/BiasAdd:0', 'conv2d_1/BiasAdd:0', 'dropout_3/cond/Merge:0', 'activation_1/Relu:0', 'activation_5/Relu:0', 'activation_2/Relu:0', 'flatten_1/Reshape:0', 'dropout_1/cond/Merge:0', 'dense_2/BiasAdd:0'])\n"
     ]
    }
   ],
   "source": [
    "# On regarde l'activation des neurones pour un echantillon test\n",
    "Echantillon = [x_test[0], x_test[1], x_test[2], x_test[3], x_test[4], x_test[5], x_test[6], x_test[7], x_test[8], x_test[9], x_test[10], x_test[11], x_test[12], x_test[13]]\n",
    "IM0 = get_activations(model0, Echantillon)\n",
    "# on affiche les noms des differentes couches\n",
    "print(IM0.keys())\n",
    "\n",
    "IM1 = get_activations(model0, Echantillon)\n",
    "print(IM1.keys())\n",
    "\n",
    "IM2 = get_activations(model0, Echantillon)\n",
    "print(IM2.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameOfTheCouche = 'activation_5/Relu:0' #name of the couche to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MI(nameOfTheCouche):\n",
    "    \n",
    "    numActivations = len(IM0[nameOfTheCouche])\n",
    "    print('number of data used for activation : '+str(numActivations))\n",
    "    numNeurons = len(IM0[nameOfTheCouche][0])\n",
    "    print('number of neurons for the layer: '+str(numNeurons))\n",
    "\n",
    "    #print(IM0[nameOfTheCouche])\n",
    "    #plt.imshow(IM0[nameOfTheCouche])\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "    # on selectionne des pair de neurones (X,Y) à comparer (regarder l'information mutuelle entre X et Y)\n",
    "    NombrePairs = 100\n",
    "\n",
    "    NeuronsSelected = numpy.zeros((NombrePairs,2))  # initialize\n",
    "\n",
    "    for i in range(NombrePairs):\n",
    "        NeuronsSelected[i] = numpy.ceil(numpy.random.rand(2)*numNeurons)  # on prend 2 neurones selectionnées aleatoirement\n",
    "        # les 2 neurones doivent être différents\n",
    "        while NeuronsSelected[i][0] == NeuronsSelected[i][1]:\n",
    "            NeuronsSelected[i] = numpy.ceil(numpy.random.rand(2)*numNeurons)\n",
    "\n",
    "    #print(NeuronsSelected[56])\n",
    "    #print(NeuronsSelected[56][0])\n",
    "    \n",
    "    MutualInfo = numpy.zeros((NombrePairs,1))  # initialization des resultats\n",
    "\n",
    "    for j in range(NombrePairs):\n",
    "        X = numpy.zeros((numActivations,1))  # initialization du vecteur X\n",
    "        Y = numpy.zeros((numActivations,1))  # initialization du vecteur y\n",
    "\n",
    "        i = 0\n",
    "        for activation in IM0[nameOfTheCouche]:   # pour chaque element de l'echantillon (= chaque activation)\n",
    "            #print(activation)\n",
    "\n",
    "            X[i] = activation[int(NeuronsSelected[j][0])-1] # on regarde l'activation du neurone selectionné\n",
    "            Y[i] = activation[int(NeuronsSelected[j][1])-1]\n",
    "\n",
    "            # On binarise : RELU\n",
    "            if X[i] > 0:\n",
    "                X[i] = 1\n",
    "            else:\n",
    "                X[i] = 0\n",
    "            if Y[i] > 0:\n",
    "                Y[i] = 1\n",
    "            else:\n",
    "                Y[i] = 0\n",
    "\n",
    "            i = i+1\n",
    "\n",
    "        X = X.flatten()\n",
    "        Y = Y.flatten()\n",
    "        #print(X)\n",
    "        #print(Y)\n",
    "\n",
    "        # example:= sklearn.metrics.normalized_mutual_info_score([1.1,1.0,1.0,1.0,0.0],[1.1,0.1,0.1,1.1,0.1])\n",
    "        MutualInfo[j] = sklearn.metrics.normalized_mutual_info_score(X,Y)\n",
    "        #print(MutualInfo[j])\n",
    "\n",
    "    return MutualInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data used for activation : 14\n",
      "number of neurons for the layer: 512\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/linux/mnovak/Documents/Thesis/Code/myenv/lib/python3.5/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "MutualInfo = MI(nameOfTheCouche)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data used for activation : 14\n",
      "number of neurons for the layer: 13\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (13,64) into shape (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-321d8560c672>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_couche\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEchantillon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdMI0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_couche\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_couche\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEchantillon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-84620c1a55cd>\u001b[0m in \u001b[0;36mMI\u001b[0;34m(nameOfTheCouche)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m#print(activation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeuronsSelected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# on regarde l'activation du neurone selectionné\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeuronsSelected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (13,64) into shape (1)"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "dMI0 = defaultdict(list)\n",
    "dMI1 = defaultdict(list)\n",
    "dMI2 = defaultdict(list)\n",
    "\n",
    "for layer_idx, name_couche in enumerate(get_activations(model0, Echantillon)):\n",
    "    dMI0[layer_idx] = MI(name_couche)\n",
    "    \n",
    "for layer_idx, name_couche in enumerate(get_activations(model1, Echantillon)):\n",
    "    dMI1[layer_idx] = MI(name_couche)\n",
    "    \n",
    "for layer_idx, name_couche in enumerate(get_activations(model2, Echantillon)):\n",
    "    dMI2[layer_idx] = MI(name_couche)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dMI = [dMI0, dMI1, dMI2]\n",
    "f, axs = plt.subplots(n_layers, 3, figsize=(15,15))\n",
    "for layer in range(n_layers):\n",
    "    for i in range(3):\n",
    "        #axs[layer,i].subplot(n_layers,3,(i+1)+layer*3)\n",
    "        axs[layer,i].hist(dMI[i][layer], bins=100, histtype='stepfilled')  # arguments are passed to np.histogram\n",
    "\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métrique Linéaire\n",
    "\n",
    "Regarder la métrique spéciale de l'article pour comparer ce qu'apporte un neurone par rapport à tous les autres neurones de la couche (! restriction linéaire)\n",
    "* https://arxiv.org/pdf/1706.05806.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
